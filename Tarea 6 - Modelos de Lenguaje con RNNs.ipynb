{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mX8gZlVyCCbz"
   },
   "source": [
    "# Laboratorio: Modelos del lenguaje con RNNs\n",
    "\n",
    "En este laboratorio, vamos a entrenar un modelo del lenguaje basado en caracteres con Recurrent Neural Networks. Asimismo, utilizaremos el modelo para generar texto. En particular, alimentaremos nuestro modelo con obras de la literatura clásica en castellano para obtener una red neuronal que sea capaz de \"escribir\" fragmentos literarios.\n",
    "\n",
    "Los entrenamientos en esta laboratorio para obtener un modelo de calidad podrían tomar cierto tiempo (5-10 minutos por epoch), por lo que se aconseja empezar a trabajar pronto. El uso de GPUs no ayuda tanto con LSTMs como con CNNs, por lo que si tenéis máquinas potentes en casa es posible que podáis entrenar más rápido o a la misma velocidad que en Colab. En todo caso, la potencia de Colab es más que suficiente para completar este laboratorio con éxito.\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d8/El_ingenioso_hidalgo_don_Quijote_de_la_Mancha.jpg\" style=\"text-align: center\" height=\"300px\"></center>\n",
    "\n",
    "El dataset a utilizar consistirá en un archivo de texto con el contenido íntegro en castellano antiguo de El Ingenioso Hidalgo Don Quijote de la Mancha, disponible de manera libre en la página de [Project Gutenberg](https://www.gutenberg.org). Asimismo, como apartado optativo en este laboratorio se pueden utilizar otras fuentes de texto. Aquí podéis descargar los datos a utilizar de El Quijote y un par de obras adicionales:\n",
    "\n",
    "[El ingenioso hidalgo Don Quijote de la Mancha (Miguel de Cervantes)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219424&authkey=AH0gb-qSo5Xd7Io)\n",
    "\n",
    "[Compilación de obras teatrales (Calderón de la Barca)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219433&authkey=AKvGD6DC3IRBqmc)\n",
    "\n",
    "[Trafalgar (Benito Pérez Galdós)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219434&authkey=AErPCAtMKOI5tYQ)\n",
    "\n",
    "Como ya deberíamos de estar acostumbrados en problemas de Machine Learning, es importante echar un vistazo a los datos antes de empezar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI274F8LQC59"
   },
   "source": [
    "## 1. Carga y procesado del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZNnzvXuqVVm"
   },
   "source": [
    "Primero, vamos a descargar el libro e inspeccionar los datos. El fichero a descargar es una versión en .txt del libro de Don Quijote, a la cual se le han borrado introducciones, licencias y otras secciones para dejarlo con el contenido real de la novela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "D7tKOZ9BFfki"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import random\n",
    "import io\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    fname=\"don_quijote.txt\", \n",
    "    origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219424&authkey=AH0gb-qSo5Xd7Io\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYGLvjLXrUUd"
   },
   "source": [
    "Una vez descargado, vamos a leer el contenido del fichero en una variable. Adicionalmente, convertiremos el contenido del texto a minúsculas para ponérselo un poco más fácil a nuestro modelo (de modo que todas las letras sean minúsculas y el modelo no necesite diferenciar entre minúsculas y mayúsculas).\n",
    "\n",
    "**1.1.** Leer todo el contenido del fichero en una única variable ***text*** y convertir el string a minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8WB6FejrrTu9"
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "\n",
    "# Abre el archivo de texto en 'path' en modo de lectura ('r') con la codificación 'utf8'\n",
    "# y asignar el objeto de archivo devuelto a la variable 'f'\n",
    "with open(path, 'r', encoding=\"utf8\") as f:\n",
    "    \n",
    "    # Lee todo el contenido del archivo de texto con el método 'read()',\n",
    "    # convierte el texto a minúsculas utilizando el método 'lower()'\n",
    "    # y asigna el resultado a la variable 'text'\n",
    "    text = f.read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_Q4YJ6ZwozR"
   },
   "source": [
    "Limpiamos los caracteres que no son necesarios del texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "T2bsVQhZwoHF"
   },
   "outputs": [],
   "source": [
    "# Cadena de caracteres inválidos que se eliminarán del texto\n",
    "invalid_chars = \"_-+.,:;'\\\"«»¡!¿?()[]{}\"\n",
    "\n",
    "# Tabla de traducción que convierte caracteres inválidos a caracteres vacíos\n",
    "change_chars = str.maketrans(\"\", \"\", invalid_chars)\n",
    "\n",
    "# Tabla de traducción para eliminar los caracteres inválidos de text\n",
    "text = text.translate(change_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkgGl8GWtUk8"
   },
   "source": [
    "Podemos comprobar ahora que efectivamente nuestra variable contiene el resultado deseado, con el comienzo tan característico del Quijote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMFhe3COFwSD",
    "outputId": "6f0b6513-50ee-4f63-ee70-10d8379b6e55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto: 2005133\n",
      "capítulo primero que trata de la condición y ejercicio del famoso hidalgo\n",
      "don quijote de la mancha\n",
      "\n",
      "\n",
      "en un lugar de la mancha de cuyo nombre no quiero acordarme no ha mucho\n",
      "tiempo que vivía un hidalgo de los de lanza en astillero adarga antigua\n",
      "rocín flaco y galgo corredor una olla de algo más vaca \n"
     ]
    }
   ],
   "source": [
    "# Longitud del texto\n",
    "print(\"Longitud del texto: {}\".format(len(text)))\n",
    "\n",
    "# Imprime los primeros 300 caracteres\n",
    "print(text[0:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZ7TUXWiyvOj"
   },
   "source": [
    "## 2. Procesado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x66_Vi_Gyxns"
   },
   "source": [
    "Una de las grandes ventajas de trabajar con modelos que utilizan caracteres en vez de palabras es que no necesitamos tokenizar el texto (partirlo palabra a palabra). Nuestro modelo funcionará directamente con los caracteres en el texto, incluyendo espacios, saltos de línea, etc.\n",
    "\n",
    "Antes de hacer nada, necesitamos procesar el texto en entradas y salidas compatibles con nuestro modelo. Como sabemos, un modelo del lenguaje con RNNs acepta una serie de caracteres y predice el siguiente carácter en la secuencia.\n",
    "\n",
    "* \"*El ingenioso don Qui*\" -> predicción: **j**\n",
    "* \"*El ingenioso don Quij*\" -> predicción: **o**\n",
    "\n",
    "De modo que la entrada y la salida de nuestro modelo necesita ser algo parecido a este esquema. En este punto, podríamos usar dos formas de preparar los datos para nuestro modelo.\n",
    "\n",
    "1. **Secuencia a secuencia**. La entrada de nuestro modelo sería una secuencia y la salida sería esa secuencia trasladada un caracter a la derecha, de modo que en cada instante de tiempo la RNN tiene que predecir el carácter siguiente. Por ejemplo:\n",
    "\n",
    ">* *Input*:   El ingenioso don Quijot \n",
    ">* *Output*: l ingenioso don Quijote\n",
    "\n",
    "2. **Secuencia a carácter**. En este variante, pasaríamos una secuencia de caracteres por nuestra RNN y, al llegar al final de la secuencia, predeciríamos el siguiente carácter.\n",
    "\n",
    ">* *Input*:   El ingenioso don Quijot \n",
    ">* *Output*: e\n",
    "\n",
    "En este laboratorio, por simplicidad, vamos a utilizar la segunda variante.\n",
    "\n",
    "De este modo, a partir del texto, hemos de generar nuestro propio training data que consista en secuencias de caracteres con el siguiente carácter a predecir. Para estandarizar las cosas, utilizaremos secuencias de tamaño *SEQ_LENGTH* caracteres (un hiperparámetro que podemos elegir nosotros).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkfJUIxW5m5C"
   },
   "source": [
    "#### 2.1. Obtención de los caracteres y mapas de caracteres\n",
    "\n",
    "Antes que nada, necesitamos saber qué caracteres aparecen en el texto, ya que tendremos que diferenciarlos mediante un índice de 0 a *num_chars* - 1 en el modelo. Obtener:\n",
    " \n",
    "\n",
    "1.   Número de caracteres únicos que aparecen en el texto.\n",
    "2.   Diccionario que asocia char a índice único entre 0 y *num_chars* - 1. Por ejemplo, {'a': 0, 'b': 1, ...}\n",
    "3.   Diccionario reverso de índices a caracteres: {0: 'a', 1: 'b', ...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmGTvLqdrq1H",
    "outputId": "a07681a8-327c-4cfa-e2a7-3ea4f02a57b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2005133"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de caracteres individuales de text\n",
    "all_chars = list(text)\n",
    "\n",
    "# Longitud de la lista resultante\n",
    "len(all_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrEWpYA8q-cZ"
   },
   "source": [
    "##### **Eliminación de caracteres especiales y creación de diccionario con los caracteres diferentes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5bJ0NsbCbupF"
   },
   "outputs": [],
   "source": [
    "# Lista con los caracteres únicos del texto\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# Diccionario que asocia cada caracter a índice único\n",
    "char_index = {c: i for i, c in enumerate(chars) if not c in invalid_chars}\n",
    "\n",
    "# Diccionario reverso de índices a caracteres\n",
    "index_char = {c: i for i, c in char_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUY_B-Gyj26W",
    "outputId": "444fa493-9d4c-40de-904e-50e73d3d93ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '0': 2,\n",
       " '1': 3,\n",
       " '2': 4,\n",
       " '3': 5,\n",
       " '4': 6,\n",
       " '5': 7,\n",
       " '6': 8,\n",
       " '7': 9,\n",
       " 'a': 10,\n",
       " 'b': 11,\n",
       " 'c': 12,\n",
       " 'd': 13,\n",
       " 'e': 14,\n",
       " 'f': 15,\n",
       " 'g': 16,\n",
       " 'h': 17,\n",
       " 'i': 18,\n",
       " 'j': 19,\n",
       " 'l': 20,\n",
       " 'm': 21,\n",
       " 'n': 22,\n",
       " 'o': 23,\n",
       " 'p': 24,\n",
       " 'q': 25,\n",
       " 'r': 26,\n",
       " 's': 27,\n",
       " 't': 28,\n",
       " 'u': 29,\n",
       " 'v': 30,\n",
       " 'w': 31,\n",
       " 'x': 32,\n",
       " 'y': 33,\n",
       " 'z': 34,\n",
       " 'à': 35,\n",
       " 'á': 36,\n",
       " 'é': 37,\n",
       " 'í': 38,\n",
       " 'ï': 39,\n",
       " 'ñ': 40,\n",
       " 'ó': 41,\n",
       " 'ù': 42,\n",
       " 'ú': 43,\n",
       " 'ü': 44}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlVJJUb_luY2",
    "outputId": "c1e13964-7d0a-4279-b71a-f18d17063242"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_B4AWo0ElwA"
   },
   "source": [
    "#### 2.2. Obtención de secuencias de entrada y carácter a predecir\n",
    "\n",
    "Ahora, vamos a obtener las secuencias de entrada en formato texto y los correspondientes caracteres a predecir. Para ello, recorrer el texto completo leído anteriormente, obteniendo una secuencia de SEQ_LENGTH caracteres y el siguiente caracter a predecir. Una vez hecho, desplazarse un carácter a la izquierda y hacer lo mismo para obtener una nueva secuencia y predicción. Guardar las secuencias en una variable ***sequences*** y los caracteres a predecir en una variable ***next_chars***.\n",
    "\n",
    "Por ejemplo, si el texto fuera \"Don Quijote\" y SEQ_LENGTH fuese 5, tendríamos\n",
    "\n",
    "* *sequences* = [\"Don Q\", \"on Qu\", \"n Qui\", \" Quij\", \"Quijo\", \"uijot\"]\n",
    "* *next_chars* = ['u', 'i', 'j', 'o', 't', 'e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NslxhnnDK6uA"
   },
   "outputs": [],
   "source": [
    "# Definición del tamaño de las secuencias\n",
    "SEQ_LENGTH = 10\n",
    "\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "step = 1 # Siguiente sentencia desplazada una palabra la izquierda\n",
    "for i in range(0, len(all_chars)-SEQ_LENGTH, step):\n",
    "    # Añade la secuencia actual a la lista de secuencias\n",
    "    sequences.append(all_chars[i:i+SEQ_LENGTH])\n",
    "    # Añade el siguiente caracter después de la secuencia actual a la lista de caracteres siguientes\n",
    "    next_chars.append(all_chars[i+SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D22jWCuasNFY",
    "outputId": "1487d12e-68a8-4887-90be-2d7a74c13f33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'l', 'e', '\\n', '\\n', '\\n', '\\n', 'f', 'i', 'n']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "SRT7kFcRsdn-",
    "outputId": "f97fe732-3154-44bc-b1ca-8c884a15fad8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Y3AmjYtHdLJ"
   },
   "source": [
    "Indicar el tamaño del training set que acabamos de generar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WVWqKxFcbwTu",
    "outputId": "f699ec9a-cdc9-4006-d7ba-cb18f55f4ce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 2005123\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño del conjunto de entrenamiento:\", len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goGQkKcwpLRJ"
   },
   "source": [
    "Como el Quijote es muy largo y tenemos muchas secuencias, podríamos encontrar problemas de memoria. Por ello, vamos a elegir un número máximo de ellas. Si estás corriendo esto localmente y tienes problemas de memoria, puedes reducir el tamaño aún más, pero ten cuidado porque, a menos datos, peor calidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "2pm1Q19ppw8F"
   },
   "outputs": [],
   "source": [
    "# Definición del máximo número de secuencias a usar\n",
    "MAX_SEQUENCES = len(sequences)\n",
    "\n",
    "# Conversión de las listas a numpy arrays para su procesamiento\n",
    "sequences, next_chars = np.array(sequences), np.array(next_chars)\n",
    "# Selecció del número máximo de secuencias para usar\n",
    "sequences, next_chars = list(sequences[:MAX_SEQUENCES]), list(next_chars[:MAX_SEQUENCES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLTO-3VMtLcZ",
    "outputId": "278d12b8-7306-4101-9f3f-c053918f6b48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'l', 'e', '\\n', '\\n', '\\n', '\\n', 'f', 'i', 'n'], dtype='<U1')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "oHIygUoJtSSB",
    "outputId": "23e65072-d37b-434f-9e63-9802cd4cb197"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FzgtAbPIs6f"
   },
   "source": [
    "#### 2.3. Obtención de input X y output y para el modelo\n",
    "\n",
    "Finalmente, a partir de los datos de entrenamiento que hemos generado vamos a crear los arrays de datos X e y que pasaremos a nuestro modelo.\n",
    "\n",
    "Para ello, **NO** vamos a utilizar *one-hot encoding* para nuestros caracteres. Por ejemplo, si sólo tuviéramos 4 caracteres (a, b, c, d), las representaciones serían: (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0) y (0, 0, 0, 1).\n",
    "\n",
    "De este modo, **X** tendrá shape *(num_sequences, seq_length, num_chars)* e **y** tendrá shape *(num_sequences, num_chars)*.\n",
    "\n",
    "Sino que usaremos **Embedings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-hot Encoding**: consiste en crear una columna binaria (que solo puede contener los valores 0 o 1) para cada valor único que exista en la variable categórica que estamos codificando, y marcar con un 1 la columna correspondiente al valor presente en cada registro, dejando las demás columnas con un valor de 0. Una desventaja de este método es que estamos aumentando la dimensionalidad del conjunto de datos (es decir, aumentando el número de columnas o características categóricas a partir de las cuales entrenar el modelo), lo que puede resultar problemático si el número de muestras de las que se dispone no es suficientemente elevado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definición de X e Y**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-OAdPD_v6U68"
   },
   "outputs": [],
   "source": [
    "# Definición de X e Y\n",
    "\n",
    "# Obtener el número de secuencias en la lista 'sequences'\n",
    "NUM_SEQUENCES = len(sequences)\n",
    "\n",
    "# Matriz 'X' llena de ceros con las dimensiones adecuadas\n",
    "# 'NUM_SEQUENCES' representa el número de secuencias en 'sequences'\n",
    "# 'SEQ_LENGTH' representa la longitud máxima de cada secuencia\n",
    "# 'len(chars)' representa el número de caracteres únicos en el conjunto de datos\n",
    "X = np.zeros((NUM_SEQUENCES, SEQ_LENGTH, len(chars)))\n",
    "\n",
    "# Matriz 'y' llena de ceros con las dimensiones adecuadas\n",
    "# 'NUM_SEQUENCES' representa el número de secuencias en 'sequences'\n",
    "# 'len(chars)' representa el número de caracteres únicos en el conjunto de datos\n",
    "y = np.zeros((NUM_SEQUENCES, len(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "MkP5lbEP4ber"
   },
   "outputs": [],
   "source": [
    "for k in range(NUM_SEQUENCES):\n",
    "    # Obtiene el siguiente caracter de cada secuencia\n",
    "    c = next_chars[k]\n",
    "    # Establece en 1 el índice correspondiente a este caracter \n",
    "    # en el vector objetivo 'y'  para la secuencia k. \n",
    "    y[k, char_index[c]] = 1\n",
    "    \n",
    "# 'char_index': diccionario que asocia cada caracter a un índice único."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "XSASk_U85Ess"
   },
   "outputs": [],
   "source": [
    "for k in range(NUM_SEQUENCES):\n",
    "    for w in range(SEQ_LENGTH):\n",
    "        # Obtiene el carácter en la posición 'w' de la secuencia 'k'\n",
    "        c = sequences[k][w]\n",
    "        # Establece en 1 el índice correspondiente a este carácter \n",
    "        # en la matriz 'X' para la secuencia k y posición w.\n",
    "        X[k, w, char_index[c]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RJEcJXQ6aCC",
    "outputId": "bd1e71f0-d657-455f-9f62-5efa20becbf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pBxTe2NS6c1g",
    "outputId": "db88a60b-f86d-49a0-e1d8-7608cd06d0d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxeUxz3HPm3l"
   },
   "source": [
    "## 3. Definición del modelo y entrenamiento\n",
    "\n",
    "Una vez tenemos ya todo preparado, es hora de definir el modelo. Define un modelo que utilice una **LSTM** con **128 unidades internas**. Si bien el modelo puede definirse de una manera más compleja, para empezar debería bastar con una LSTM más una capa Dense con el *softmax* que predice el siguiente caracter a producir. Adam puede ser una buena elección de optimizador.\n",
    "\n",
    "Una vez el modelo esté definido, entrénalo un poco para asegurarte de que la loss es decreciente. No es necesario guardar la salida de este entrenamiento en el entregable final, ya que vamos a hacer el entrenamiento más informativo en el siguiente punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSw2j0btYWZs",
    "outputId": "e1a4b0d2-56c5-4386-8317-aaeaf7441e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               89088     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              132096    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 45)                46125     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 267,309\n",
      "Trainable params: 267,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "# Capa LSTM con 128 unidades\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(char_index))))\n",
    "# Capa densa con 1024 unidades y función de activación relu\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "# Capa densa con tantas unidades como caracteres únicos y función de activación softmax\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "# Muestra un resumen del modelo\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "gCAgWd2Z8la3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14882/14882 [==============================] - 305s 20ms/step - loss: 0.0140 - accuracy: 0.4976 - val_loss: 0.0128 - val_accuracy: 0.5475\n",
      "Epoch 2/5\n",
      "14882/14882 [==============================] - 294s 20ms/step - loss: 0.0122 - accuracy: 0.5700 - val_loss: 0.0121 - val_accuracy: 0.5756\n",
      "Epoch 3/5\n",
      "14882/14882 [==============================] - 295s 20ms/step - loss: 0.0117 - accuracy: 0.5869 - val_loss: 0.0118 - val_accuracy: 0.5852\n",
      "Epoch 4/5\n",
      "14882/14882 [==============================] - 294s 20ms/step - loss: 0.0115 - accuracy: 0.5967 - val_loss: 0.0116 - val_accuracy: 0.5926\n",
      "Epoch 5/5\n",
      "14882/14882 [==============================] - 292s 20ms/step - loss: 0.0113 - accuracy: 0.6026 - val_loss: 0.0115 - val_accuracy: 0.5967\n"
     ]
    }
   ],
   "source": [
    "# Compilación del modelo\n",
    "model.compile(loss='MSE', optimizer='adam', metrics=['accuracy'])\n",
    "# Entrenamiento del modelo y registro del historial\n",
    "history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=5, shuffle=True).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X a predecir**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "3oT7pNvjrP2e"
   },
   "outputs": [],
   "source": [
    "# X a predecir\n",
    "X_pred = np.zeros((1, SEQ_LENGTH, len(chars)))\n",
    "X_pred[0,0] = X[0,0]\n",
    "X_pred[0,1] = X[0,1]\n",
    "X_pred[0,2] = X[0,2]\n",
    "X_pred[0,3] = X[0,3]\n",
    "X_pred[0,4] = X[0,4]\n",
    "X_pred[0,5] = X[0,5]\n",
    "X_pred[0,6] = X[0,6]\n",
    "X_pred[0,7] = X[0,7]\n",
    "X_pred[0,8] = X[0,8]\n",
    "X_pred[0,9] = X[0,9]\n",
    "\n",
    "# Predicción del siguiente caracter\n",
    "prediccion = model.predict(X_pred, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.79704749e-04, 7.33007537e-03, 2.48895347e-04, 2.28706980e-04,\n",
       "        9.88617321e-05, 2.62180081e-04, 1.29823835e-04, 1.16870149e-04,\n",
       "        1.66574100e-04, 1.60652795e-04, 1.61076561e-01, 2.07205987e-04,\n",
       "        8.22628965e-04, 2.24684575e-03, 2.21271232e-01, 2.81279237e-04,\n",
       "        1.25042989e-03, 5.54673315e-04, 2.95986608e-02, 1.29991525e-03,\n",
       "        2.68333927e-02, 1.06988288e-03, 2.76961620e-03, 2.95817167e-01,\n",
       "        4.17921838e-04, 2.34358246e-04, 1.18135326e-01, 4.75485390e-03,\n",
       "        1.40146585e-03, 9.67003256e-02, 6.14372082e-04, 8.20773639e-05,\n",
       "        4.05388360e-04, 9.49737674e-04, 8.10292040e-05, 1.62865865e-04,\n",
       "        2.44862447e-03, 3.98424407e-03, 3.35194683e-03, 2.38597728e-04,\n",
       "        2.63080263e-04, 8.74996930e-03, 3.02797445e-04, 2.50580744e-03,\n",
       "        9.34070849e-05]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caracter asociado al índice de mayor valor, en el vector de predicción, en el diccionario\n",
    "index_char[np.argmax(prediccion)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_char[np.argmax(X[1,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62661/62661 [==============================] - 298s 5ms/step - loss: 0.0111 - accuracy: 0.6096\n"
     ]
    }
   ],
   "source": [
    "# Evalua el rendimiento del modelo en el conjunto de datos de entrenamiento (X,y)\n",
    "results = model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicción para una frase\n",
    "\n",
    "Para ver cómo evoluciona nuestro modelo del lenguaje, vamos a generar texto según va entrenando. Para ello, vamos a programar una función que, utilizando el modelo en su estado actual, genere texto, con la idea de ver cómo se va generando texto al entrenar cada epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función generate_text\n",
    "def generate_text(length):\n",
    "    X_pred[0,0] = X[0,0]\n",
    "    X_pred[0,1] = X[0,1]\n",
    "    X_pred[0,2] = X[0,2]\n",
    "    X_pred[0,3] = X[0,3]\n",
    "    X_pred[0,4] = X[0,4]\n",
    "    X_pred[0,5] = X[0,5]\n",
    "    X_pred[0,6] = X[0,6]\n",
    "    X_pred[0,7] = X[0,7]\n",
    "    X_pred[0,8] = X[0,8]\n",
    "    X_pred[0,9] = X[0,9]\n",
    "    # Itera por cada carácter en el texto generado\n",
    "    for t in range(length):\n",
    "        # Predicción con el modelo entrenado y se obtiene el siguiente carácter\n",
    "        prediccion = model.predict(X_pred, batch_size=32, verbose=0)\n",
    "        next_pred = index_char[np.argmax(prediccion)]\n",
    "        # Se desplazan los caracteres en X_pred para poder añadir el siguiente carácter generado\n",
    "        for k in range(10):\n",
    "             X_pred[0, k-1] = X_pred[0, k]\n",
    "        # Imprime el siguiente carácter generado\n",
    "        print(next_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o\n",
      "o\n",
      "b\n",
      "i\n",
      "s\n",
      "u\n",
      "l\n",
      "o\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Generación de las siguiente 10 letras\n",
    "generate_text(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBbmz9DMhVhc"
   },
   "source": [
    "## Entregable\n",
    "\n",
    "Completa los apartados anteriores para entrenar modelos del lenguaje que sean capaces de generar texto con cierto sentido. Comentar los resultados obtenidos y cómo el modelo va mejorando época a época. Comentar las diferencias apreciadas al utilizar diferentes valores de temperatura. Entregar al menos la salida de un entrenamiento completo con los textos generados época a época.\n",
    "\n",
    "El objetivo no es conseguir generar pasajes literarios con coherencia, sino obtener lenguaje que se asemeje en cierta manera a lo visto en el texto original y donde las palabras sean reconocibles como construcciones en castellano. Como ejemplo de lo que se puede conseguir, este es el resultado de generar texto después de 10 epochs y con temperature 0.2:\n",
    "\n",
    "\n",
    "```\n",
    "-----> Epoch: 10 - Generando texto con temperature 0.2\n",
    "Seed: o le cautivaron y rindieron el\n",
    "Texto generado: o le cautivaron y rindieron el caballero de la caballería de la mano de la caballería del cual se le dijo:\n",
    "\n",
    "-¿quién es el verdad de la caballería de la caballería de la caballería de la caballería de la caballería, y me ha de habían de la mano que el caballero de la mano de la caballería. y que no se le habían de la mano de la c\n",
    "\n",
    "```\n",
    "\n",
    "Asimismo, se proponen los siguientes aspectos opcionales para conseguir nota extra:\n",
    "\n",
    "*   Experimentar con los textos de teatro en verso de Calderón de la Barca (¿es capaz el modelo de aprender las estructuras del teatro en verso?) o con alguno de los otros textos disponibles. También se puede probar con textos de vuestra elección.\n",
    "*   Experimentar con distintos valores de SEQ_LENGTH.\n",
    "*   Experimentar con los hiperparámetros del modelo o probar otro tipo de modelos como GRUs o *stacked* RNNs (RNNs apiladas).\n",
    "*   Experimentar utilizando embeddings en vez de representaciones one-hot.\n",
    "*   (Difícil) Entrenar un modelo secuencia a secuencia en vez de secuencia a carácter.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Mnuz1HJ36fA-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
